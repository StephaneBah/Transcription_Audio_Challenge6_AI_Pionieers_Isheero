# ğŸ™ï¸ Transcription Audio avec Whisper - Challenge 6 AI Pioneers

<div align="center">
  
![Whisper](https://img.shields.io/badge/Whisper-OpenAI-brightgreen)
![Python](https://img.shields.io/badge/Python-3.8+-blue)
![Status](https://img.shields.io/badge/Status-Active-success)

</div>

**[ğŸ”— AccÃ©der Ã  l'application de collecte d'audio](https://collecte-audio-production-3da5.up.railway.app/)**

**[ğŸš€ Le modÃ¨le fine-tunÃ© est disponible ici](https://huggingface.co/StephaneBah/whisper-tiny-rad-fr)**

**[ğŸ“– PrÃ©sentation de l'architecture Whisper](https://presentation-de-larchite-e93v5v7.gamma.site/)**

**[ğŸ“‚ Docs sur Whisper](https://en.wikipedia.org/wiki/Whisper_%28speech_recognition_system%29)**


## ğŸ“‹ Vue d'ensemble

Ce projet utilise le modÃ¨le **Whisper** pour effectuer la transcription automatique de fichiers audio en texte. Il comprend deux tÃ¢ches principales : 
1. **ğŸ”„ Fine-tuning du modÃ¨le Whisper** sur un corpus spÃ©cifique.
2. **ğŸ“Š Ã‰valuation des performances** du modÃ¨le sur des donnÃ©es de test.

## ğŸ“‚ Structure du projet

| Fichier | Description |
|---------|-------------|
| **`main.py`** | Point d'entrÃ©e principal pour lancer le fine-tuning ou l'Ã©valuation des performances |
| **`whisper_fine_tuning.py`** | Script pour le fine-tuning du modÃ¨le Whisper |
| **`whisper_perf_test.py`** | Script pour tester les performances du modÃ¨le Whisper |
| **`utils.py`** | Fonctions utilitaires pour la manipulation des donnÃ©es audio et du modÃ¨le |
| **`requirements.txt`** | Liste des dÃ©pendances nÃ©cessaires |
| **`dico_corpus.json`** | Fichier contenant les mÃ©tadonnÃ©es des fichiers audio et leurs transcriptions |

---

## âš™ï¸ PrÃ©requis

<details open>
<summary><b>ğŸ› ï¸ Environnement requis</b></summary>
<br>

1. **ğŸ Python** : Assurez-vous d'avoir Python 3.10 ou une version ultÃ©rieure installÃ©e <=3.12
2. **ğŸ–¥ï¸ CUDA** : Si vous souhaitez utiliser un GPU, installez CUDA et configurez PyTorch pour l'utiliser.
3. **ğŸ¬ FFmpeg** : Installez FFmpeg pour le traitement des fichiers audio :
   ```bash
   sudo apt update && sudo apt install ffmpeg
   ```
</details>

## ğŸš€ Installation

<details open>
<summary><b>Ã‰tapes d'installation</b></summary>
<br>

### Etape 1: Cloner le dÃ©pÃ´t
```bash
git clone <URL_DU_DEPOT>
cd Transcription_Audio_Challence6_AI_Pionieers_Isheero
```

### Etape 2: CrÃ©er un environnement virtuel
```bash
sudo apt install python3.12-venv #(optionnel et dÃ©pend de votre version de python)
python3 -m venv venv
source venv/bin/activate  # Sur Windows : venv\Scripts\activate
```

### Etape 3: Installer les dÃ©pendances

#### PrÃ©requis pour les dÃ©pendances
```bash
# Installer cURL & tar & autres (optionnel)
sudo apt update && sudo apt install curl tar 
sudo apt install -y pkg-config libssl-dev build-essential


# Installer Rust (nÃ©cessaire pour tokenizers) (optionnel)
curl https://sh.rustup.rs -sSf | sh
source "$HOME/.cargo/env"

# Installer d'autres dÃ©pendances de compilation
sudo apt update && sudo apt install -y build-essential python3-dev
```

#### Option A: Installation avec pip
```bash
pip install --upgrade setuptools wheel pip
pip install numpy==2.2.0
pip install -r requirements.txt
pip install git+https://github.com/openai/whisper.git
```

#### Option B: Installation avec UV (plus rapide)
```bash
# Installer UV
curl -LsSf https://astral.sh/uv/install.sh | sh

# Installer les dÃ©pendances avec UV
uv venv venv  # CrÃ©er un environnement virtuel (si ce n'est pas dÃ©jÃ  fait)
source venv/bin/activate  # Sur Windows : venv\Scripts\activate
uv pip install --upgrade setuptools wheel
uv pip install numpy==2.2.0
uv pip install -r requirements.txt
uv pip install git+https://github.com/openai/whisper.git
```
</details>

### Etape 4: Configuration de l'API HuggingFace

CrÃ©ez un compte sur [HuggingFace](https://huggingface.co)
GÃ©nÃ©rez un jeton d'API [ici](https://huggingface.co/settings/tokens).
InsÃ©rez dans le fichier `.env` la ligne suivante :
```properties
HF_TOKEN = votre_jeton_huggingface
```

## ğŸ“ Utilisation

### ğŸ”„ Fine-tuning du modÃ¨le Whisper

Pour lancer le fine-tuning du modÃ¨le Whisper, utilisez la commande suivante:

```bash
python main.py train --model tiny --output-dir ./whisper-tiny-rad-fr
```

<details>
<summary><b>Options disponibles</b></summary>
<br>

| Option | Description | DÃ©faut |
|--------|-------------|--------|
| `--model` | Taille du modÃ¨le Ã  utiliser ('tiny', 'base', 'small', 'medium', 'large') | 'tiny' |
| `--audio-path` | Chemin vers le dossier contenant les fichiers audio | './Collecte_Audio_Challence6_AI_Pionieers_Isheero' |
| `--language` | Code de langue Ã  utiliser | 'fr' |
| `--output-dir` | Dossier oÃ¹ sauvegarder le modÃ¨le fine-tunÃ© | './whisper-tiny-rad-fr' |
| `--push-to-hub` | Ajouter ce flag pour pousser le modÃ¨le sur Hugging Face Hub | - |
| `--freeze-encoder` | Ajouter ce flag pour geler l'encodeur pendant le fine-tuning | - |

</details>

**Exemple avec toutes les options:**
```bash
python main.py train --model small --audio-path ./mon_dossier_audio --language fr --output-dir ./mon_modele_fine_tune --push-to-hub --freeze-encoder
```

### ğŸ“Š Test de performances du modÃ¨le

Pour Ã©valuer les performances du modÃ¨le Whisper (prÃ©-entrainÃ© ou fine-tunÃ©), utilisez:

```bash
python main.py test --model base --output-file transcription_results.csv
```
NB: Pour le moment, les commandes sont configurÃ©s pour tester que les modÃ¨les prÃ©-entraÃ®nÃ©s de Whisper.

<details>
<summary><b>Options disponibles</b></summary>
<br>

| Option | Description | DÃ©faut |
|--------|-------------|--------|
| `--model` | Taille du modÃ¨le Ã  utiliser ('tiny', 'base', 'small', 'medium', 'large') | 'base' |
| `--audio-path` | Chemin vers le dossier contenant les fichiers audio | './Collecte_Audio_Challence6_AI_Pionieers_Isheero' |
| `--language` | Code de langue Ã  utiliser | 'fr' |
| `--output-file` | Fichier CSV oÃ¹ sauvegarder les rÃ©sultats | 'transcription_results.csv' |

</details>

**Exemple avec toutes les options:**
```bash
python main.py test --model large --audio-path ./mon_dossier_audio --language fr --output-file mes_resultats.csv
```

## ğŸ§  Utilisation d'un modÃ¨le fine-tunÃ©

Pour utiliser un modÃ¨le que vous avez fine-tunÃ© (stockÃ© localement), vous pouvez modifier le code dans `whisper_perf_test.py` pour charger le modÃ¨le depuis le dossier oÃ¹ il a Ã©tÃ© sauvegardÃ©.

## ğŸ“ˆ RÃ©sultats

- Les rÃ©sultats des transcriptions et les scores WER (Word Error Rate) sont sauvegardÃ©s dans un fichier CSV (dÃ©fini par l'option `--output-file`).
- Les mÃ©triques d'entraÃ®nement et de validation sont suivies avec TensorBoard.

Pour visualiser les mÃ©triques avec TensorBoard :
```bash
tensorboard --logdir=./whisper-tiny-rad-fr
```

---

<div align="center">
  
DÃ©veloppÃ© dans le cadre du **Challenge 6 AI Pioneers - Isheero** ğŸš€

</div>

