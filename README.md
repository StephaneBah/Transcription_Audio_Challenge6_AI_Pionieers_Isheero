# üéôÔ∏è Transcription Audio avec Whisper - Challenge 6 AI Pioneers

<div align="center">
  
![Whisper](https://img.shields.io/badge/Whisper-OpenAI-brightgreen)
![Python](https://img.shields.io/badge/Python-3.8+-blue)
![Status](https://img.shields.io/badge/Status-Active-success)

</div>

**[üîó Acc√©der √† l'application de collecte d'audio](https://collecte-audio-production-3da5.up.railway.app/)**

**[üìñ Pr√©sentation de l'architecture Whisper](https://presentation-de-larchite-e93v5v7.gamma.site/)**

**[üìÇ Docs sur Whisper](https://en.wikipedia.org/wiki/Whisper_%28speech_recognition_system%29)**


## üìã Vue d'ensemble

Ce projet utilise le mod√®le **Whisper** pour effectuer la transcription automatique de fichiers audio en texte. Il comprend deux t√¢ches principales : 
1. **üîÑ Fine-tuning du mod√®le Whisper** sur un corpus sp√©cifique.
2. **üìä √âvaluation des performances** du mod√®le sur des donn√©es de test.

## üìÇ Structure du projet

| Fichier | Description |
|---------|-------------|
| **`main.py`** | Point d'entr√©e principal pour lancer le fine-tuning ou l'√©valuation des performances |
| **`whisper_fine_tuning.py`** | Script pour le fine-tuning du mod√®le Whisper |
| **`whisper_perf_test.py`** | Script pour tester les performances du mod√®le Whisper |
| **`utils.py`** | Fonctions utilitaires pour la manipulation des donn√©es audio et du mod√®le |
| **`requirements.txt`** | Liste des d√©pendances n√©cessaires |
| **`dico_corpus.json`** | Fichier contenant les m√©tadonn√©es des fichiers audio et leurs transcriptions |

---

## ‚öôÔ∏è Pr√©requis

<details open>
<summary><b>üõ†Ô∏è Environnement requis</b></summary>
<br>

1. **üêç Python** : Assurez-vous d'avoir Python 3.10 ou une version ult√©rieure install√©e <=3.12
2. **üñ•Ô∏è CUDA** : Si vous souhaitez utiliser un GPU, installez CUDA et configurez PyTorch pour l'utiliser.
3. **üé¨ FFmpeg** : Installez FFmpeg pour le traitement des fichiers audio :
   ```bash
   sudo apt update && sudo apt install ffmpeg
   ```
</details>

## üöÄ Installation

<details open>
<summary><b>√âtapes d'installation</b></summary>
<br>

### Etape 1: Cloner le d√©p√¥t
```bash
git clone <URL_DU_DEPOT>
cd Transcription_Audio_Challence6_AI_Pionieers_Isheero
```

### Etape 2: Cr√©er un environnement virtuel
```bash
sudo apt install python3.12-venv #(optionnel et d√©pend de votre version de python)
python3 -m venv venv
source venv/bin/activate  # Sur Windows : venv\Scripts\activate
```

### Etape 3: Installer les d√©pendances

#### Pr√©requis pour les d√©pendances
```bash
# Installer cURL & tar & autres (optionnel)
sudo apt update && sudo apt install curl tar 
sudo apt install -y pkg-config libssl-dev build-essential


# Installer Rust (n√©cessaire pour tokenizers) (optionnel)
curl https://sh.rustup.rs -sSf | sh
source "$HOME/.cargo/env"

# Installer d'autres d√©pendances de compilation
sudo apt update && sudo apt install -y build-essential python3-dev
```

#### Option A: Installation avec pip
```bash
pip install --upgrade setuptools wheel pip
pip install numpy==2.2.0
pip install -r requirements.txt
pip install git+https://github.com/openai/whisper.git
```

#### Option B: Installation avec UV (plus rapide)
```bash
# Installer UV
curl -LsSf https://astral.sh/uv/install.sh | sh

# Installer les d√©pendances avec UV
uv venv venv  # Cr√©er un environnement virtuel (si ce n'est pas d√©j√† fait)
source venv/bin/activate  # Sur Windows : venv\Scripts\activate
uv pip install --upgrade setuptools wheel
uv pip install numpy==2.2.0
uv pip install -r requirements.txt
uv pip install git+https://github.com/openai/whisper.git
```
</details>

### Etape 4: Configuration de l'API HuggingFace

Cr√©ez un compte sur [HuggingFace](https://huggingface.co)
G√©n√©rez un jeton d'API [ici](https://huggingface.co/settings/tokens).
Ins√©rez dans le fichier `.env` la ligne suivante :
```properties
HF_TOKEN = votre_jeton_huggingface
```

## üìù Utilisation

### üîÑ Fine-tuning du mod√®le Whisper

Pour lancer le fine-tuning du mod√®le Whisper, utilisez la commande suivante:

```bash
python main.py train --model tiny --output-dir ./whisper-tiny-rad-fr
```

<details>
<summary><b>Options disponibles</b></summary>
<br>

| Option | Description | D√©faut |
|--------|-------------|--------|
| `--model` | Taille du mod√®le √† utiliser ('tiny', 'base', 'small', 'medium', 'large') | 'tiny' |
| `--audio-path` | Chemin vers le dossier contenant les fichiers audio | './Collecte_Audio_Challence6_AI_Pionieers_Isheero' |
| `--language` | Code de langue √† utiliser | 'fr' |
| `--output-dir` | Dossier o√π sauvegarder le mod√®le fine-tun√© | './whisper-tiny-rad-fr' |
| `--push-to-hub` | Ajouter ce flag pour pousser le mod√®le sur Hugging Face Hub | - |
| `--freeze-encoder` | Ajouter ce flag pour geler l'encodeur pendant le fine-tuning | - |

</details>

**Exemple avec toutes les options:**
```bash
python main.py train --model small --audio-path ./mon_dossier_audio --language fr --output-dir ./mon_modele_fine_tune --push-to-hub --freeze-encoder
```

### üìä Test de performances du mod√®le

Pour √©valuer les performances du mod√®le Whisper (pr√©-entrain√© ou fine-tun√©), utilisez:

```bash
python main.py test --model base --output-file transcription_results.csv
```
NB: Pour le moment, les commandes sont configur√©s pour tester que les mod√®les pr√©-entra√Æn√©s de Whisper.

<details>
<summary><b>Options disponibles</b></summary>
<br>

| Option | Description | D√©faut |
|--------|-------------|--------|
| `--model` | Taille du mod√®le √† utiliser ('tiny', 'base', 'small', 'medium', 'large') | 'base' |
| `--audio-path` | Chemin vers le dossier contenant les fichiers audio | './Collecte_Audio_Challence6_AI_Pionieers_Isheero' |
| `--language` | Code de langue √† utiliser | 'fr' |
| `--output-file` | Fichier CSV o√π sauvegarder les r√©sultats | 'transcription_results.csv' |

</details>

**Exemple avec toutes les options:**
```bash
python main.py test --model large --audio-path ./mon_dossier_audio --language fr --output-file mes_resultats.csv
```

## üß† Utilisation d'un mod√®le fine-tun√©

Pour utiliser un mod√®le que vous avez fine-tun√© (stock√© localement), vous pouvez modifier le code dans `whisper_perf_test.py` pour charger le mod√®le depuis le dossier o√π il a √©t√© sauvegard√©.

## üìà R√©sultats

- Les r√©sultats des transcriptions et les scores WER (Word Error Rate) sont sauvegard√©s dans un fichier CSV (d√©fini par l'option `--output-file`).
- Les m√©triques d'entra√Ænement et de validation sont suivies avec TensorBoard.

Pour visualiser les m√©triques avec TensorBoard :
```bash
tensorboard --logdir=./whisper-tiny-rad-fr
```

---

<div align="center">
  
D√©velopp√© dans le cadre du **Challenge 6 AI Pioneers - Isheero** üöÄ

</div>

